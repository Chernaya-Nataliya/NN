{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, SimpleRNN, Dense\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка и предобработка текста\n",
    "with open('poiziya.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    text = text.replace('\\ufeff', '') \n",
    "    text = re.sub(r'[^А-я ]', '', text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8568"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_characters = 34\n",
    "tokenizer = Tokenizer(num_words=num_characters, char_level=True)\n",
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_chars = 6\n",
    "data = tokenizer.texts_to_matrix(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data.shape[0]-inp_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8562"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([data[i:i+inp_chars, :] for i in range(n)])\n",
    "Y = data[inp_chars:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8562"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_15 (SimpleRNN)   (None, 6, 512)            280064    \n",
      "                                                                 \n",
      " simple_rnn_16 (SimpleRNN)   (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 34)                17442     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 822,306\n",
      "Trainable params: 822,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Создание модели SimpleRNN\n",
    "model = Sequential()\n",
    "model.add(Input((inp_chars, num_characters)))\n",
    "model.add(SimpleRNN(512, activation='tanh', return_sequences=True)) # Изменение размера слоя SimpleRNN\n",
    "model.add(SimpleRNN(512, activation='tanh')) # Добавление дополнительного слоя SimpleRNN\n",
    "model.add(Dense(num_characters, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 2.0776 - accuracy: 0.3750\n",
      "Epoch 2/150\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 1.9708 - accuracy: 0.3997\n",
      "Epoch 3/150\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.8623 - accuracy: 0.4283\n",
      "Epoch 4/150\n",
      "134/134 [==============================] - 5s 35ms/step - loss: 1.7430 - accuracy: 0.4702\n",
      "Epoch 5/150\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 1.6273 - accuracy: 0.4985\n",
      "Epoch 6/150\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 1.4857 - accuracy: 0.5447\n",
      "Epoch 7/150\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 1.3646 - accuracy: 0.5786\n",
      "Epoch 8/150\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.2427 - accuracy: 0.6171\n",
      "Epoch 9/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0986 - accuracy: 0.6615\n",
      "Epoch 10/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.9784 - accuracy: 0.7052\n",
      "Epoch 11/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8984 - accuracy: 0.7310\n",
      "Epoch 12/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.7909 - accuracy: 0.7675\n",
      "Epoch 13/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6978 - accuracy: 0.8045\n",
      "Epoch 14/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.6374 - accuracy: 0.8234\n",
      "Epoch 15/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5815 - accuracy: 0.8427\n",
      "Epoch 16/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5393 - accuracy: 0.8511\n",
      "Epoch 17/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.5295 - accuracy: 0.8589\n",
      "Epoch 18/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4884 - accuracy: 0.8667\n",
      "Epoch 19/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.4730 - accuracy: 0.8737\n",
      "Epoch 20/150\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.4621 - accuracy: 0.8765\n",
      "Epoch 21/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.4572 - accuracy: 0.8694\n",
      "Epoch 22/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4513 - accuracy: 0.8746\n",
      "Epoch 23/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.4381 - accuracy: 0.8785\n",
      "Epoch 24/150\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4295 - accuracy: 0.8804\n",
      "Epoch 25/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.4301 - accuracy: 0.8804\n",
      "Epoch 26/150\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.4251 - accuracy: 0.8802\n",
      "Epoch 27/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.4332 - accuracy: 0.8777\n",
      "Epoch 28/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4132 - accuracy: 0.8857\n",
      "Epoch 29/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4110 - accuracy: 0.8855\n",
      "Epoch 30/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.4087 - accuracy: 0.8848\n",
      "Epoch 31/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.4086 - accuracy: 0.8837\n",
      "Epoch 32/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3983 - accuracy: 0.8876\n",
      "Epoch 33/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4065 - accuracy: 0.8839\n",
      "Epoch 34/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.4230 - accuracy: 0.8798\n",
      "Epoch 35/150\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4137 - accuracy: 0.8795\n",
      "Epoch 36/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4071 - accuracy: 0.8838\n",
      "Epoch 37/150\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4053 - accuracy: 0.8813\n",
      "Epoch 38/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3945 - accuracy: 0.8853\n",
      "Epoch 39/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3801 - accuracy: 0.8901\n",
      "Epoch 40/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3866 - accuracy: 0.8876\n",
      "Epoch 41/150\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3801 - accuracy: 0.8878\n",
      "Epoch 42/150\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.3808 - accuracy: 0.8864\n",
      "Epoch 43/150\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.3806 - accuracy: 0.8882\n",
      "Epoch 44/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3964 - accuracy: 0.8833\n",
      "Epoch 45/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4002 - accuracy: 0.8819\n",
      "Epoch 46/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3915 - accuracy: 0.8836\n",
      "Epoch 47/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3898 - accuracy: 0.8862\n",
      "Epoch 48/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3817 - accuracy: 0.8892\n",
      "Epoch 49/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3803 - accuracy: 0.8889\n",
      "Epoch 50/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3777 - accuracy: 0.8847\n",
      "Epoch 51/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3846 - accuracy: 0.8836\n",
      "Epoch 52/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3791 - accuracy: 0.8914\n",
      "Epoch 53/150\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.3738 - accuracy: 0.8900\n",
      "Epoch 54/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3771 - accuracy: 0.8878\n",
      "Epoch 55/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3836 - accuracy: 0.8871\n",
      "Epoch 56/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3872 - accuracy: 0.8832\n",
      "Epoch 57/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3690 - accuracy: 0.8896\n",
      "Epoch 58/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3716 - accuracy: 0.8910\n",
      "Epoch 59/150\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3692 - accuracy: 0.8883\n",
      "Epoch 60/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3775 - accuracy: 0.8860\n",
      "Epoch 61/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3539 - accuracy: 0.8899\n",
      "Epoch 62/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3769 - accuracy: 0.8859\n",
      "Epoch 63/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3876 - accuracy: 0.8817\n",
      "Epoch 64/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3840 - accuracy: 0.8811\n",
      "Epoch 65/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3905 - accuracy: 0.8804\n",
      "Epoch 66/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3720 - accuracy: 0.8844\n",
      "Epoch 67/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3661 - accuracy: 0.8879\n",
      "Epoch 68/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3802 - accuracy: 0.8825\n",
      "Epoch 69/150\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.3762 - accuracy: 0.8880\n",
      "Epoch 70/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3774 - accuracy: 0.8865\n",
      "Epoch 71/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3855 - accuracy: 0.8813\n",
      "Epoch 72/150\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3782 - accuracy: 0.8833\n",
      "Epoch 73/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3837 - accuracy: 0.8816\n",
      "Epoch 74/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3736 - accuracy: 0.8879\n",
      "Epoch 75/150\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.3621 - accuracy: 0.8878\n",
      "Epoch 76/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3692 - accuracy: 0.8876\n",
      "Epoch 77/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3792 - accuracy: 0.8833\n",
      "Epoch 78/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3778 - accuracy: 0.8833\n",
      "Epoch 79/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3682 - accuracy: 0.8854\n",
      "Epoch 80/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3712 - accuracy: 0.8831\n",
      "Epoch 81/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3705 - accuracy: 0.8844\n",
      "Epoch 82/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3638 - accuracy: 0.8883\n",
      "Epoch 83/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3763 - accuracy: 0.8820\n",
      "Epoch 84/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3822 - accuracy: 0.8799\n",
      "Epoch 85/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3751 - accuracy: 0.8799\n",
      "Epoch 86/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3686 - accuracy: 0.8831\n",
      "Epoch 87/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3675 - accuracy: 0.8854\n",
      "Epoch 88/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3607 - accuracy: 0.8854\n",
      "Epoch 89/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3598 - accuracy: 0.8892\n",
      "Epoch 90/150\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3800 - accuracy: 0.8812\n",
      "Epoch 91/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3695 - accuracy: 0.8854\n",
      "Epoch 92/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3616 - accuracy: 0.8875\n",
      "Epoch 93/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3581 - accuracy: 0.8904\n",
      "Epoch 94/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3651 - accuracy: 0.8844\n",
      "Epoch 95/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3751 - accuracy: 0.8791\n",
      "Epoch 96/150\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.3816 - accuracy: 0.8801\n",
      "Epoch 97/150\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 0.3684 - accuracy: 0.8844\n",
      "Epoch 98/150\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.3570 - accuracy: 0.8867\n",
      "Epoch 99/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3742 - accuracy: 0.8840\n",
      "Epoch 100/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3624 - accuracy: 0.8874\n",
      "Epoch 101/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3587 - accuracy: 0.8895\n",
      "Epoch 102/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3703 - accuracy: 0.8820\n",
      "Epoch 103/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3525 - accuracy: 0.8909\n",
      "Epoch 104/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3676 - accuracy: 0.8854\n",
      "Epoch 105/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3714 - accuracy: 0.8811\n",
      "Epoch 106/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3780 - accuracy: 0.8799\n",
      "Epoch 107/150\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.3737 - accuracy: 0.8817\n",
      "Epoch 108/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3814 - accuracy: 0.8826\n",
      "Epoch 109/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3628 - accuracy: 0.8830\n",
      "Epoch 110/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3735 - accuracy: 0.8841\n",
      "Epoch 111/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3813 - accuracy: 0.8839\n",
      "Epoch 112/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3981 - accuracy: 0.8753\n",
      "Epoch 113/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3775 - accuracy: 0.8825\n",
      "Epoch 114/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3711 - accuracy: 0.8812\n",
      "Epoch 115/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3695 - accuracy: 0.8831\n",
      "Epoch 116/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3692 - accuracy: 0.8852\n",
      "Epoch 117/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3550 - accuracy: 0.8871\n",
      "Epoch 118/150\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.3604 - accuracy: 0.8861\n",
      "Epoch 119/150\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.3627 - accuracy: 0.8818\n",
      "Epoch 120/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3576 - accuracy: 0.8869\n",
      "Epoch 121/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3672 - accuracy: 0.8831\n",
      "Epoch 122/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3786 - accuracy: 0.8755\n",
      "Epoch 123/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3839 - accuracy: 0.8783\n",
      "Epoch 124/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3680 - accuracy: 0.8824\n",
      "Epoch 125/150\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3700 - accuracy: 0.8817\n",
      "Epoch 126/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3876 - accuracy: 0.8794\n",
      "Epoch 127/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3702 - accuracy: 0.8846\n",
      "Epoch 128/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3662 - accuracy: 0.8843\n",
      "Epoch 129/150\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 0.3669 - accuracy: 0.8845\n",
      "Epoch 130/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3571 - accuracy: 0.8866\n",
      "Epoch 131/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3669 - accuracy: 0.8847\n",
      "Epoch 132/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3686 - accuracy: 0.8834\n",
      "Epoch 133/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3535 - accuracy: 0.8866\n",
      "Epoch 134/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3624 - accuracy: 0.8827\n",
      "Epoch 135/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3613 - accuracy: 0.8820\n",
      "Epoch 136/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3631 - accuracy: 0.8864\n",
      "Epoch 137/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3695 - accuracy: 0.8829\n",
      "Epoch 138/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3780 - accuracy: 0.8758\n",
      "Epoch 139/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3683 - accuracy: 0.8824\n",
      "Epoch 140/150\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.3696 - accuracy: 0.8811\n",
      "Epoch 141/150\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.3643 - accuracy: 0.8848\n",
      "Epoch 142/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3670 - accuracy: 0.8837\n",
      "Epoch 143/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3809 - accuracy: 0.8792\n",
      "Epoch 144/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3668 - accuracy: 0.8822\n",
      "Epoch 145/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3741 - accuracy: 0.8808\n",
      "Epoch 146/150\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3794 - accuracy: 0.8786\n",
      "Epoch 147/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3752 - accuracy: 0.8809\n",
      "Epoch 148/150\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3837 - accuracy: 0.8783\n",
      "Epoch 149/150\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3605 - accuracy: 0.8848\n",
      "Epoch 150/150\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.3713 - accuracy: 0.8822\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "history = model.fit(X, Y, batch_size=64, epochs=150) # Увеличение количества эпох и размера пакета\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация текста\n",
    "def buildPhrase(inp_str, str_len=50):\n",
    "    for i in range(str_len):\n",
    "        if len(inp_str) >= inp_chars:  # Проверяем, достаточно ли символов для создания входной последовательности\n",
    "            x = []\n",
    "            for j in range(i, i+inp_chars):\n",
    "                x.append(tokenizer.texts_to_matrix(inp_str[j]))\n",
    "            x = np.array(x)\n",
    "            inp = x.reshape(1, inp_chars, num_characters)\n",
    "            pred = model.predict(inp)\n",
    "            d = tokenizer.index_word[pred.argmax(axis=1)[0]]\n",
    "            inp_str += d\n",
    "    return inp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "родителили и т липикь т нина ь гс оявд  ирп нонилуеи   з  \n"
     ]
    }
   ],
   "source": [
    "res = buildPhrase(\"родители\")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
